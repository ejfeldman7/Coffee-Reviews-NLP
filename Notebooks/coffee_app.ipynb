{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit Application\n",
    "\n",
    "Streamlit application for deploying coffee recommender, score predictor, and review generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipreqs  --savepath C:\\Users\\ejfel\\Documents\\metis_repos\\Coffee-Reviews-NLP/requirements.txt .//__temp_pipreqsnb_folder/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully saved requirements file in C:\\Users\\ejfel\\Documents\\metis_repos\\Coffee-Reviews-NLP/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# !pip install pipreqsnb\n",
    "!pipreqsnb C:\\Users\\ejfel\\Documents\\metis_repos\\Coffee-Reviews-NLP\\coffee.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ejfel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "2021-03-10 08:32:23.825 WARNING root: \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ejfel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "with open('coffee_words.pickle','rb') as read_file:\n",
    "    coffee = pickle.load(read_file)\n",
    "with open('coffee_ratings.pickle','rb') as read_file:\n",
    "    ratings = pickle.load(read_file)\n",
    "with open('combined.pickle','rb') as read_file:\n",
    "    combined = pickle.load(read_file)\n",
    "with open('df_full.pickle','rb') as read_file:\n",
    "    df = pickle.load(read_file)\n",
    "with open('df_topic_breakdown.pickle','rb') as read_file:\n",
    "    df_topic_breakdown = pickle.load(read_file)\n",
    "with open('sentiment.pickle','rb') as read_file:\n",
    "    sentiment = pickle.load(read_file)\n",
    "with open('generating_reviews.pickle','rb') as read_file:\n",
    "    generating_reviews = pickle.load(read_file)\n",
    "\n",
    "with open('blindtfidf_vec.pickle', 'rb') as read_file:\n",
    "    blindtfidf = pickle.load(read_file)\n",
    "with open('blindtfidf_mat.pickle', 'rb') as read_file:\n",
    "    tfidf_blind = pickle.load(read_file)\n",
    "ratings = ratings.reset_index().rename(columns={'index':'Roaster'})\n",
    "\n",
    "with open('nmf_tfidfblind.pickle', 'rb') as read_file:\n",
    "    nmf_tfidfblind = pickle.load(read_file)\n",
    "\n",
    "with open('blindvectorizer.pickle', 'rb') as read_file:\n",
    "    blindvectorizer = pickle.load(read_file)\n",
    "with open('blindtfidf_topic.pickle', 'rb') as read_file:\n",
    "    blindtfidf_topic = pickle.load(read_file)\n",
    "with open('blindtopic_tfidf.pickle', 'rb') as read_file:\n",
    "    blindtopic_tfidf = pickle.load(read_file)\n",
    "\n",
    "\n",
    "with open('words_to_score_rf.pickle','rb') as read_file:\n",
    "    rfr = pickle.load(read_file)\n",
    "with open('num_to_score_RF.pickle','rb') as read_file:\n",
    "    rfr_num = pickle.load(read_file)\n",
    "with open('words_to_score_linear.pickle','rb') as read_file:\n",
    "    lm = pickle.load(read_file)\n",
    "with open('subcats_to_score_lasso.pickle','rb') as read_file:\n",
    "    lasso = pickle.load(read_file)\n",
    "with open('lm_aroma.pickle','rb') as read_file:\n",
    "    lm_aroma = pickle.load(read_file)\n",
    "with open('lm_acidity.pickle','rb') as read_file:\n",
    "    lm_acidity = pickle.load(read_file)\n",
    "with open('lm_aftertaste.pickle','rb') as read_file:\n",
    "    lm_aftertaste = pickle.load(read_file)\n",
    "with open('lm_flavor.pickle','rb') as read_file:\n",
    "    lm_flavor = pickle.load(read_file)\n",
    "with open('lm_body.pickle','rb') as read_file:\n",
    "    lm_body = pickle.load(read_file)\n",
    "\n",
    "import os.path\n",
    "\n",
    "# create a button in the side bar that will move to the next page/radio button choice\n",
    "next = st.sidebar.button('Next on list')\n",
    "\n",
    "# will use this list and next button to increment page, MUST BE in the SAME order\n",
    "# as the list passed to the radio button\n",
    "new_choice = ['Home','Recommender','Score from Text','Score from Score','Generated Reviews']\n",
    "\n",
    "# This is what makes this work, check directory for a pickled file that contains\n",
    "# the index of the page you want displayed, if it exists, then you pick up where the\n",
    "#previous run through of your Streamlit Script left off,\n",
    "# if it's the first go it's just set to 0\n",
    "if os.path.isfile('next.p'):\n",
    "    next_clicked = pickle.load(open('next.p', 'rb'))\n",
    "    # check if you are at the end of the list of pages\n",
    "    if next_clicked == len(new_choice):\n",
    "        next_clicked = 0 # go back to the beginning i.e. homepage\n",
    "else:\n",
    "    next_clicked = 0 #the start\n",
    "\n",
    "# this is the second tricky bit, check to see if the person has clicked the\n",
    "# next button and increment our index tracker (next_clicked)\n",
    "if next:\n",
    "    #increment value to get to the next page\n",
    "    next_clicked = next_clicked +1\n",
    "\n",
    "    # check if you are at the end of the list of pages again\n",
    "    if next_clicked == len(new_choice):\n",
    "        next_clicked = 0 # go back to the beginning i.e. homepage\n",
    "\n",
    "# create your radio button with the index that we loaded\n",
    "choice = st.sidebar.radio(\"go to\",('Home','Recommender','Score from Text','Score from Score','Generated Reviews'), index=next_clicked)\n",
    "\n",
    "# pickle the index associated with the value, to keep track if the radio button has been used\n",
    "pickle.dump(new_choice.index(choice), open('next.p', 'wb'))\n",
    "\n",
    "# finally get to whats on each page\n",
    "if choice == 'Home':\n",
    "    st.title('Welcome to my data analysis app for coffee reviews!')\n",
    "    '''On the side bar on the left you will find a few different applications'''\n",
    "    '''\n",
    "    1. This is the __Home Page__\n",
    "    2. Use the __Recommender__ app to get a coffee recommendation based on your flavor description\n",
    "    3. Use the __Score from Text__ app to generate a prediction for overall and subcategory score based on a coffee's description\n",
    "    4. Use the __ Score from Scores__ app to generate an overall score prediction based on subcategory scores\n",
    "    5. Use the __Generated Reviews__ app to create a computer generated review for a coffee depending on different flavor attributes\n",
    "    '''\n",
    "    \n",
    "elif choice == 'Recommender':\n",
    "    st.title('Coffee Recommender')\n",
    "    st.write('Get a new coffee recommendation')\n",
    "    # Format inputs\n",
    "    user_coffee_description = st.text_input(\"Give a couple sentences here of how you describe your ideal coffee. Try to include as much as you can about your desired flavor profile.\", '')\n",
    "    text = [user_coffee_description]\n",
    "    doc_topic = blindtfidf_topic\n",
    "    vt = blindtfidf.transform(text).todense()\n",
    "    tt1 = nmf_tfidfblind.transform(vt)\n",
    "\n",
    "    #Find Recommendations\n",
    "    indices = pairwise_distances(tt1.reshape(1,-1),doc_topic,metric='cosine').argsort()\n",
    "    recs = list(indices[0][0:4])\n",
    "    # df_topic_breakdown.iloc[recs]\n",
    "    # st.write('The coffee you liked was described as:',t[0])\n",
    "    st.write('\\n')\n",
    "    if user_coffee_description == '':\n",
    "        st.write('Excited to recommend a coffee for you!')\n",
    "    else:\n",
    "        st.write('Based on your input coffee, I recommend you try:','\\n\\n',ratings.iloc[recs[0]]['Roaster'],'who roast a bean from',ratings.iloc[recs[0]]['Coffee Origin'],'.','\\n\\n','It could be desribed as:','\\n\\n',coffee.iloc[recs[0]].Review)\n",
    "\n",
    "elif choice == 'Score from Text':\n",
    "    st.title('Score Predictor')\n",
    "    st.write('Predict coffee scores from reviews')\n",
    "    \n",
    "    user_coffee_description = st.text_input(\"Provide a couple sentence descripton of the flavors, acid level, aroma, aftertaste, and body of your coffee.\", '')\n",
    "    user_text = [user_coffee_description]\n",
    "    vt = blindtfidf.transform(user_text).todense()\n",
    "    tt1 = nmf_tfidfblind.transform(vt)\n",
    "\n",
    "    word_count = pd.DataFrame()\n",
    "    word_count['text'] = user_text\n",
    "    word_count['length'] = word_count.text.str.replace(r'\\d+','',regex=True).str.len()\n",
    "    word_count['word count'] = pd.DataFrame(blindvectorizer.transform(user_text).toarray()).sum(axis=1)[0]\n",
    "    word_count.drop(columns='text',inplace=True)\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_vector = pd.DataFrame()\n",
    "    sentiment_vector['text'] = user_text\n",
    "    sentiment_vector['scores'] = sentiment_vector.text.apply(lambda Text: sid.polarity_scores(Text))\n",
    "    sentiment_vector['pos']  = sentiment_vector['scores'].apply(lambda score_dict: score_dict['pos'])\n",
    "    sentiment_vector['neg']  = sentiment_vector['scores'].apply(lambda score_dict: score_dict['neg'])\n",
    "    sentiment_vector['compound']  = sentiment_vector['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "    sentiment_vector.drop(columns=['text','scores'],inplace=True)\n",
    "\n",
    "    attributes = pd.concat([sentiment_vector,word_count],axis=1)\n",
    "    attributes = pd.concat([attributes,pd.DataFrame(tt1)],axis=1)\n",
    "\n",
    "\n",
    "    overall = lm.predict(attributes)\n",
    "    aroma = lm_aroma.predict(attributes)\n",
    "    acidity = lm_acidity.predict(attributes)\n",
    "    aftertaste = lm_aftertaste.predict(attributes)\n",
    "    flavor = lm_flavor.predict(attributes)\n",
    "    body = lm_body.predict(attributes)\n",
    "\n",
    "    if user_coffee_description == '':\n",
    "        st.write('Excited to predict the score of your coffee!')\n",
    "    else:\n",
    "        st.write('Based on your input coffee, I predict it to receive a score of:',overall[0].round(2),'\\n\\n',\n",
    "                'An aroma score of (out of 10):',aroma[0].round(2),'\\n\\n',\n",
    "                'An acidity score of (out of 10):',acidity[0].round(2),'\\n\\n',\n",
    "                'An aftertaste score of (out of 10):',aftertaste[0].round(2),'\\n\\n',\n",
    "                'A flavor score of (out of 10):',flavor[0].round(2),'\\n\\n',\n",
    "                'A body score of (out of 10):',body[0].round(2))\n",
    "\n",
    "elif choice == 'Score from Score':\n",
    "    st.title('Score Predictor (if you have the details)')\n",
    "    st.write('Predict an overall score from subcategories')\n",
    "    \n",
    "    aroma = st.slider('aroma',min_value=1,max_value=10,step=1)\n",
    "    body = st.slider('body',min_value=1,max_value=10,step=1)\n",
    "    flavor = st.slider('flavor',min_value=1,max_value=10,step=1)\n",
    "    aftertaste = st.slider('aftertaste',min_value=1,max_value=10,step=1)\n",
    "    acidity = st.slider('acidity',min_value=1,max_value=10,step=1)\n",
    "\n",
    "    features = ['aroma', 'body', 'flavor', 'aftertaste', 'acidity']\n",
    "    df_feat = pd.DataFrame(columns = features)\n",
    "    df_feat.aroma = [aroma]\n",
    "    df_feat.body = [body]\n",
    "    df_feat.flavor = [flavor]\n",
    "    df_feat.aftertaste = [aftertaste]\n",
    "    df_feat.acidity = [acidity]\n",
    "\n",
    "    overall = rfr_num.predict(df_feat)[0].round(2)\n",
    "    st.write('With subcategory scores as shown above, I predict your coffee to be review overall as:',overall)\n",
    "\n",
    "elif choice == 'Generated Reviews':\n",
    "    st.title('Review Generator')\n",
    "    st.write('Generate a rough draft review based on past reviews in the category')    \n",
    "\n",
    "    first = st.checkbox(\"Coffee Type: Smooth, Citrus, Floral\")\n",
    "    second = st.checkbox(\"Coffee Type: Dark, Chocolate, Roast, Wood \")\n",
    "    third = st.checkbox(\"Coffee Type: Sweet, Almond, Tart, Zest\")\n",
    "    fourth = st.checkbox(\"Coffee Type: Cacao, Nutty, Dried Fruit, Clean\")\n",
    "    fifth = st.checkbox(\"Coffee Type: Sweet, Hazelnut, Resinous\")\n",
    "    sixth = st.checkbox(\"Coffee Type: Juicy, Acidic, Cacao, Nectar\")\n",
    "    seventh = st.checkbox(\"Coffee Type: Red Berries\")\n",
    "    eighth = st.checkbox(\"Coffee Type: Caramel, Nutty, Woody\")\n",
    "    ninth = st.checkbox(\"Coffee Type: Cherry, Vinuous, Chocolate\")\n",
    "\n",
    "    def markov_chain(corpus):\n",
    "        #tokenize text into words\n",
    "        words = []\n",
    "        for review in corpus:\n",
    "            words += review.split(' ')\n",
    "\n",
    "        # initialize a default dictionary to hold all of the words and next words\n",
    "        word_dict = defaultdict(list)\n",
    "\n",
    "        # create a zipped list of all of the word pairs and put them in word: list of next words format\n",
    "        for first, second in list(zip(words,words[1:])):\n",
    "            word_dict[first].append(second)\n",
    "\n",
    "        return dict(word_dict)\n",
    "\n",
    "    def generate_review(corpus, n_words=30):\n",
    "        start = random.choice(list(corpus.keys())).capitalize()\n",
    "        sentence = []\n",
    "        sentence.append(start)\n",
    "        for _ in range(n_words):\n",
    "            next_word = random.choice(list(corpus[sentence[-1].lower()]))\n",
    "            sentence.append(next_word)\n",
    "\n",
    "        return ' '.join(sentence)+'.'  \n",
    "\n",
    "    text_list = []\n",
    "    if first:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 0].review]\n",
    "    elif second:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 1].review]\n",
    "    elif third:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 2].review]\n",
    "    elif fourth:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 3].review]\n",
    "    elif fifth:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 4].review]\n",
    "    elif sixth:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 5].review]\n",
    "    elif seventh:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 6].review]\n",
    "    elif eighth:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 7].review]\n",
    "    elif ninth:\n",
    "        text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 8].review]\n",
    "\n",
    "    if text_list == []:\n",
    "        st.write('Pick a coffee type or combine a few to see a (rough) computer generated review!')\n",
    "    else:\n",
    "        st.write(generate_review(markov_chain(text_list)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st.title('Coffee Review Recommendations and Analysis')    \n",
    "\n",
    "# # st.write(\"Using a radio button restricts selection to only one option at a time.\")\n",
    "# # neighborhood = st.radio(\"Neighborhood\", df.neighbourhood_group.unique())\n",
    "# # show_exp = st.checkbox(\"Include expensive listings\")\n",
    "# # Set up model\n",
    "# doc_word = tfidf_blind\n",
    "\n",
    "# nmf_model = nmf_tfidfblind\n",
    "# doc_topic = blindtfidf_topic\n",
    "# topic_word = nmf_model.components_\n",
    "\n",
    "# words = blindtfidf.get_feature_names()\n",
    "# t = nmf_model.components_.argsort(axis=1)[:,-1:-7:-1]\n",
    "\n",
    "# topic_words = [[words[e] for e in l] for l in t]\n",
    "\n",
    "# # First checkbox: coffee recommender\n",
    "\n",
    "# if st.checkbox('Get a recommendation for coffee from a description'):\n",
    "#     # Format inputs\n",
    "#     user_coffee_description = st.text_input(\"Give a couple sentences here of how you describe your ideal coffee. Try to include as much as you can about your desired flavor profile.\", '')\n",
    "#     text = [user_coffee_description]\n",
    "#     vt = blindtfidf.transform(text).todense()\n",
    "#     tt1 = nmf_model.transform(vt)\n",
    "\n",
    "#     #Find Recommendations\n",
    "#     indices = pairwise_distances(tt1.reshape(1,-1),doc_topic,metric='cosine').argsort()\n",
    "#     recs = list(indices[0][0:4])\n",
    "#     # df_topic_breakdown.iloc[recs]\n",
    "#     # st.write('The coffee you liked was described as:',t[0])\n",
    "#     st.write('\\n')\n",
    "#     if user_coffee_description == '':\n",
    "#         st.write('Excited to recommend a coffee for you!')\n",
    "#     else:\n",
    "#         st.write('Based on your input coffee, I recommend you try:','\\n\\n',ratings.iloc[recs[0]]['Roaster'],'who roast a bean from',ratings.iloc[recs[0]]['Coffee Origin'],'.','\\n\\n','It could be desribed as:','\\n\\n',coffee.iloc[recs[0]].Review)\n",
    "\n",
    "# # Second checkbox: coffee scorer\n",
    "# if st.checkbox('Predict overall and category score predictions for a coffee description'):\n",
    "#     user_coffee_description = st.text_input(\"Provide a couple sentence descripton of the flavors, acid level, aroma, aftertaste, and body of your coffee.\", '')\n",
    "#     user_text = [user_coffee_description]\n",
    "#     vt = blindtfidf.transform(user_text).todense()\n",
    "#     tt1 = nmf_model.transform(vt)\n",
    "    \n",
    "#     word_count = pd.DataFrame()\n",
    "#     word_count['text'] = user_text\n",
    "#     word_count['length'] = word_count.text.str.replace(r'\\d+','',regex=True).str.len()\n",
    "#     word_count['word count'] = pd.DataFrame(blindvectorizer.transform(user_text).toarray()).sum(axis=1)[0]\n",
    "#     word_count.drop(columns='text',inplace=True)\n",
    "    \n",
    "#     sid = SentimentIntensityAnalyzer()\n",
    "#     sentiment_vector = pd.DataFrame()\n",
    "#     sentiment_vector['text'] = user_text\n",
    "#     sentiment_vector['scores'] = sentiment_vector.text.apply(lambda Text: sid.polarity_scores(Text))\n",
    "#     sentiment_vector['pos']  = sentiment_vector['scores'].apply(lambda score_dict: score_dict['pos'])\n",
    "#     sentiment_vector['neg']  = sentiment_vector['scores'].apply(lambda score_dict: score_dict['neg'])\n",
    "#     sentiment_vector['compound']  = sentiment_vector['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "#     sentiment_vector.drop(columns=['text','scores'],inplace=True)\n",
    "    \n",
    "#     attributes = pd.concat([sentiment_vector,word_count],axis=1)\n",
    "#     attributes = pd.concat([attributes,pd.DataFrame(tt1)],axis=1)\n",
    "\n",
    "    \n",
    "#     overall = lm.predict(attributes)\n",
    "#     aroma = lm_aroma.predict(attributes)\n",
    "#     acidity = lm_acidity.predict(attributes)\n",
    "#     aftertaste = lm_aftertaste.predict(attributes)\n",
    "#     flavor = lm_flavor.predict(attributes)\n",
    "#     body = lm_body.predict(attributes)\n",
    "\n",
    "#     if user_coffee_description == '':\n",
    "#         st.write('Excited to predict the score of your coffee!')\n",
    "#     else:\n",
    "#         st.write('Based on your input coffee, I predict it to receive a score of:',overall[0].round(2),'\\n\\n',\n",
    "#                 'An aroma score of (out of 10):',aroma[0].round(2),'\\n\\n',\n",
    "#                 'An acidity score of (out of 10):',acidity[0].round(2),'\\n\\n',\n",
    "#                 'An aftertaste score of (out of 10):',aftertaste[0].round(2),'\\n\\n',\n",
    "#                 'A flavor score of (out of 10):',flavor[0].round(2),'\\n\\n',\n",
    "#                 'A body score of (out of 10):',body[0].round(2))\n",
    "\n",
    "        \n",
    "\n",
    "# # Third checkbox: coffee scorer if you know the underlying category scores...\n",
    "# if st.checkbox('Predict overall score for a coffee based on its subcategory scores'):\n",
    "#     aroma = st.slider('aroma',min_value=1,max_value=10,step=1)\n",
    "#     body = st.slider('body',min_value=1,max_value=10,step=1)\n",
    "#     flavor = st.slider('flavor',min_value=1,max_value=10,step=1)\n",
    "#     aftertaste = st.slider('aftertaste',min_value=1,max_value=10,step=1)\n",
    "#     acidity = st.slider('acidity',min_value=1,max_value=10,step=1)\n",
    "    \n",
    "#     features = ['aroma', 'body', 'flavor', 'aftertaste', 'acidity']\n",
    "#     df_feat = pd.DataFrame(columns = features)\n",
    "#     df_feat.aroma = [aroma]\n",
    "#     df_feat.body = [body]\n",
    "#     df_feat.flavor = [flavor]\n",
    "#     df_feat.aftertaste = [aftertaste]\n",
    "#     df_feat.acidity = [acidity]\n",
    "    \n",
    "#     overall = rfr_num.predict(df_feat)[0].round(2)\n",
    "#     st.write('With subcategory scores as shown above, I predict your coffee to be review overall as:',overall)\n",
    "\n",
    "# # Fourth checkbox: computer generated review for a coffee...\n",
    "# if st.checkbox('Generate a review for a coffee based on which group it falls into'): \n",
    "    \n",
    "#     first = st.checkbox(\"Coffee Type: 1\")\n",
    "#     second = st.checkbox(\"Coffee Type: 2\")\n",
    "#     third = st.checkbox(\"Coffee Type: 3\")\n",
    "#     fourth = st.checkbox(\"Coffee Type: 4\")\n",
    "#     fifth = st.checkbox(\"Coffee Type: 5\")\n",
    "#     sixth = st.checkbox(\"Coffee Type: 6\")\n",
    "#     seventh = st.checkbox(\"Coffee Type: 7\")\n",
    "#     eighth = st.checkbox(\"Coffee Type: 8\")\n",
    "#     ninth = st.checkbox(\"Coffee Type: 9\")\n",
    "    \n",
    "#     def markov_chain(corpus):\n",
    "#         #tokenize text into words\n",
    "#         words = []\n",
    "#         for review in corpus:\n",
    "#             words += review.split(' ')\n",
    "\n",
    "#         # initialize a default dictionary to hold all of the words and next words\n",
    "#         word_dict = defaultdict(list)\n",
    "\n",
    "#         # create a zipped list of all of the word pairs and put them in word: list of next words format\n",
    "#         for first, second in list(zip(words,words[1:])):\n",
    "#             word_dict[first].append(second)\n",
    "\n",
    "#         return dict(word_dict)\n",
    "\n",
    "#     def generate_review(corpus, n_words=50):\n",
    "#         start = random.choice(list(corpus.keys())).capitalize()\n",
    "#         sentence = []\n",
    "#         sentence.append(start)\n",
    "#         for _ in range(n_words):\n",
    "#             next_word = random.choice(list(corpus[sentence[-1].lower()]))\n",
    "#             sentence.append(next_word)\n",
    "\n",
    "#         return ' '.join(sentence)+'.'  \n",
    "    \n",
    "#     text_list = []\n",
    "#     if first:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 0].review]\n",
    "#     elif second:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 1].review]\n",
    "#     elif third:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 2].review]\n",
    "#     elif fourth:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 3].review]\n",
    "#     elif fifth:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 4].review]\n",
    "#     elif sixth:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 5].review]\n",
    "#     elif seventh:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 6].review]\n",
    "#     elif eighth:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 7].review]\n",
    "#     elif ninth:\n",
    "#         text_list = text_list + [review.lower() for review in generating_reviews[generating_reviews.group == 8].review]\n",
    "\n",
    "#     if text_list == []:\n",
    "#         st.write('Pick a coffee type to see a computer generated review!')\n",
    "#     else:\n",
    "#         st.write(generate_review(markov_chain(text_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
