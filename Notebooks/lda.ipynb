{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ejfel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ejfel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coffee_words.pickle','rb') as read_file:\n",
    "    coffee = pickle.load(read_file)\n",
    "with open('coffee_ratings.pickle','rb') as read_file:\n",
    "    ratings = pickle.load(read_file)\n",
    "with open('combined.pickle','rb') as read_file:\n",
    "    combined = pickle.load(read_file)\n",
    "with open('df.pickle','rb') as read_file:\n",
    "    df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roaster</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jackrabbit Java</td>\n",
       "      <td>Yeasty, richly sweet-savory. Fresh-baked bread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jackrabbit Java</td>\n",
       "      <td>Balanced, sweet-toned, floral. Tea rose, cocoa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Rooster Coffee Roaster</td>\n",
       "      <td>Delicate, deep; complex. Pomegranate, macadami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paradise Roasters</td>\n",
       "      <td>Very sweet, floral-toned. Freesia, pink grapef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kakalove Cafe</td>\n",
       "      <td>Opulent, richly sweet-tart-savory. Black curra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>The Coffee Beanery</td>\n",
       "      <td>A light-medium-roasted blend with power: The a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>Starbucks Coffee</td>\n",
       "      <td>The rest of the taste profile plays peek-a-boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5956</th>\n",
       "      <td>Peerless Coffee</td>\n",
       "      <td>Given the medium roast, the carbon notes here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>Gevalia</td>\n",
       "      <td>For such a relatively light roast, not particu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>Café Godiva</td>\n",
       "      <td>This coffee arrived pre-ground (not available ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5959 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Roaster  \\\n",
       "0                Jackrabbit Java   \n",
       "1                Jackrabbit Java   \n",
       "2     Red Rooster Coffee Roaster   \n",
       "3              Paradise Roasters   \n",
       "4                  Kakalove Cafe   \n",
       "...                          ...   \n",
       "5954          The Coffee Beanery   \n",
       "5955            Starbucks Coffee   \n",
       "5956             Peerless Coffee   \n",
       "5957                     Gevalia   \n",
       "5958                 Café Godiva   \n",
       "\n",
       "                                                   Text  \n",
       "0     Yeasty, richly sweet-savory. Fresh-baked bread...  \n",
       "1     Balanced, sweet-toned, floral. Tea rose, cocoa...  \n",
       "2     Delicate, deep; complex. Pomegranate, macadami...  \n",
       "3     Very sweet, floral-toned. Freesia, pink grapef...  \n",
       "4     Opulent, richly sweet-tart-savory. Black curra...  \n",
       "...                                                 ...  \n",
       "5954  A light-medium-roasted blend with power: The a...  \n",
       "5955  The rest of the taste profile plays peek-a-boo...  \n",
       "5956  Given the medium roast, the carbon notes here ...  \n",
       "5957  For such a relatively light roast, not particu...  \n",
       "5958  This coffee arrived pre-ground (not available ...  \n",
       "\n",
       "[5959 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Roaster'] = coffee['Roaster']\n",
    "df['TextA'] = coffee.Review + coffee.Notes + coffee.TLDR\n",
    "df['TextB'] = df.TextA.str.replace('[^ ]+\\.[^ ]+','',regex=True)\n",
    "df['Text'] = df.TextB.str.replace(r'Visit.*\\n?','',regex=True)\n",
    "df.drop(columns=['TextA','TextB'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.Text\n",
    "  \n",
    "# raw documents to tf-idf matrix: \n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                             use_idf=True, \n",
    "                             smooth_idf=True)\n",
    "# SVD to reduce dimensionality: \n",
    "svd_model = TruncatedSVD(n_components=100,         #// num dimensions\n",
    "                         algorithm='randomized',\n",
    "                         n_iter=10)\n",
    "# pipeline of tf-idf + SVD, fit to and applied to documents:\n",
    "svd_transformer = Pipeline([('tfidf', vectorizer), \n",
    "                            ('svd', svd_model)])\n",
    "svd_matrix = svd_transformer.fit_transform(documents)\n",
    "# svd_matrix can later be used to compare documents, compare words, or compare queries with documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp38-cp38-win_amd64.whl (24.2 MB)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\ejfel\\anaconda3\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\ejfel\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-4.2.0.tar.gz (119 kB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\ejfel\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-4.2.0-py3-none-any.whl size=109637 sha256=2b5bfd7dc24d2dc3b4b2154e8e71b77f8bb6a14476bfd1b16acca7e0286b197e\n",
      "  Stored in directory: c:\\users\\ejfel\\appdata\\local\\pip\\cache\\wheels\\24\\f6\\ea\\70a0761bdfaeacff66662751fe71920e25c4c43d97098a3886\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.21\n",
      "    Uninstalling Cython-0.29.21:\n",
      "      Successfully uninstalled Cython-0.29.21\n",
      "Successfully installed Cython-0.29.14 gensim-3.8.3 smart-open-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wiki_en_wordids.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0b7229c85b48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# load id->word mapping (the dictionary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mid2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wiki_en_wordids.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# load corpus iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMmCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wiki_en_tfidf.mm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\corpora\\dictionary.py\u001b[0m in \u001b[0;36mload_from_text\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \"\"\"\n\u001b[0;32m    681\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wiki_en_wordids.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "from gensim.corpora import Dictionary\n",
    "# from gensim.corpora.Dictionary import load_from_text, doc2bow\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "document = df.Text\n",
    "# load id->word mapping (the dictionary)\n",
    "id2word = Dictionary.load_from_text('wiki_en_wordids.txt')\n",
    "# load corpus iterator\n",
    "mm = MmCorpus('wiki_en_tfidf.mm')\n",
    "# extract 100 LDA topics, updating once every 10,000\n",
    "lda = LdaModel(corpus=mm, id2word=id2word, num_topics=100, update_every=1, chunksize=10000, passes=1)\n",
    "# use LDA model: transform new doc to bag-of-words, then apply lda\n",
    "doc_bow = Dictionary.doc2bow(document.split())\n",
    "doc_lda = lda[doc_bow]\n",
    "# doc_lda is vector of length num_topics representing weighted presence of each topic in the doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA from new site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, stop_words = 'english',max_df=3200)\n",
    "doc_word = vectorizer.fit_transform(df.Text.str.replace(r'\\d+','',regex=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the corpus\n",
    "count_vectorizer = CountVectorizer(min_df=10, max_df=3200, ngram_range=(1,1), stop_words='english')\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=10, max_df=3200, ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "# calculate the feature matrix\n",
    "feature_matrix = count_vectorizer.fit_transform(df.Text.str.replace(r'\\d+','',regex=True))\n",
    "tfidf_feature_matrix = tfidf_vectorizer.fit_transform(df.Text.str.replace(r'\\d+','',regex=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82106008, 0.17893992],\n",
       "       [0.83884816, 0.16115184],\n",
       "       [0.9878912 , 0.0121088 ],\n",
       "       ...,\n",
       "       [0.0141855 , 0.9858145 ],\n",
       "       [0.01430916, 0.98569084],\n",
       "       [0.01325895, 0.98674105]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5959, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Instantiate the LDA model\n",
    "lda_model = LatentDirichletAllocation(n_components=2, max_iter=100, learning_method='online', random_state=43,\n",
    "                                     batch_size=128, evaluate_every=-1, n_jobs=-1)\n",
    "\n",
    "# fit transform the feature matrix\n",
    "lda_output = lda_model.fit_transform(feature_matrix)\n",
    "\n",
    "# display the lda_output and its shape\n",
    "display(lda_output)\n",
    "display(lda_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define Search Param\n",
    "search_params = {'n_components': [2, 3, 4, 5, 10, 15, 20, 25], 'learning_decay': [.5, .7, .9]}\n",
    "\n",
    "# Init the model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search class\n",
    "model = GridSearchCV(lda, search_params)\n",
    "\n",
    "model.fit(feature_matrix)\n",
    "best_lda_model = model.best_estimator_\n",
    "print(\"Best model's params: \", model.best_params_)\n",
    "print(\"Best log likelihood score: \", model.best_score_)\n",
    "print(\"Model perplexity: \", best_lda_model.perplexity(feature_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_results = pd.DataFrame(model.cv_results_)\n",
    "df_cv_results.to_csv(\"LDAGridSearchResults.csv\", header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x=\"param_n_components\", y=\"mean_test_score\", hue=\"param_learning_decay\", data=df_cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document to topic matrix\n",
    "lda_output = best_lda_model.transform(feature_matrix)\n",
    "# column names\n",
    "topicnames = ['Topic_' + str(i) for i in range(best_lda_model.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = ['Doc_' + str(i) for i in range(len(clean_reviews_text))]\n",
    "\n",
    "# create a dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output,2), columns=topicnames, index=docnames)\n",
    "\n",
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dominant topic\n",
    "df_document_topic['dominant_topic'] = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_document_topic.dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roaster</th>\n",
       "      <th>origin</th>\n",
       "      <th>roast_level</th>\n",
       "      <th>group</th>\n",
       "      <th>rating</th>\n",
       "      <th>aroma</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jackrabbit Java</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jackrabbit Java</td>\n",
       "      <td>Nyamasheke District, Rwanda</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Rooster Coffee Roaster</td>\n",
       "      <td>Los Naranjos, La Argentina, Huila Department, ...</td>\n",
       "      <td>Light</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paradise Roasters</td>\n",
       "      <td>Huila, Colombia</td>\n",
       "      <td>Light</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kakalove Cafe</td>\n",
       "      <td>Antioquia Department, Colombia</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      roaster  \\\n",
       "0             Jackrabbit Java   \n",
       "1             Jackrabbit Java   \n",
       "2  Red Rooster Coffee Roaster   \n",
       "3           Paradise Roasters   \n",
       "4               Kakalove Cafe   \n",
       "\n",
       "                                              origin   roast_level  group  \\\n",
       "0                                         Costa Rica  Medium-Light      1   \n",
       "1                        Nyamasheke District, Rwanda  Medium-Light      0   \n",
       "2  Los Naranjos, La Argentina, Huila Department, ...         Light      0   \n",
       "3                                    Huila, Colombia         Light      0   \n",
       "4                     Antioquia Department, Colombia  Medium-Light      1   \n",
       "\n",
       "   rating  aroma  body  flavor  aftertaste  acidity  \n",
       "0      93    9.0   9.0     9.0         8.0      8.0  \n",
       "1      92    9.0   8.0     9.0         8.0      8.0  \n",
       "2      96    9.0   9.0    10.0         9.0      9.0  \n",
       "3      95    9.0   9.0     9.0         9.0      9.0  \n",
       "4      95    9.0   9.0     9.0         9.0      9.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejfel\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roaster</th>\n",
       "      <th>origin</th>\n",
       "      <th>roast_level</th>\n",
       "      <th>group</th>\n",
       "      <th>rating</th>\n",
       "      <th>aroma</th>\n",
       "      <th>body</th>\n",
       "      <th>flavor</th>\n",
       "      <th>aftertaste</th>\n",
       "      <th>acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jackrabbit Java</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jackrabbit Java</td>\n",
       "      <td>Nyamasheke District, Rwanda</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red Rooster Coffee Roaster</td>\n",
       "      <td>Los Naranjos, La Argentina, Huila Department, ...</td>\n",
       "      <td>Light</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paradise Roasters</td>\n",
       "      <td>Huila, Colombia</td>\n",
       "      <td>Light</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kakalove Cafe</td>\n",
       "      <td>Antioquia Department, Colombia</td>\n",
       "      <td>Medium-Light</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      roaster  \\\n",
       "0             Jackrabbit Java   \n",
       "1             Jackrabbit Java   \n",
       "2  Red Rooster Coffee Roaster   \n",
       "3           Paradise Roasters   \n",
       "4               Kakalove Cafe   \n",
       "\n",
       "                                              origin   roast_level  group  \\\n",
       "0                                         Costa Rica  Medium-Light      1   \n",
       "1                        Nyamasheke District, Rwanda  Medium-Light      0   \n",
       "2  Los Naranjos, La Argentina, Huila Department, ...         Light      0   \n",
       "3                                    Huila, Colombia         Light      0   \n",
       "4                     Antioquia Department, Colombia  Medium-Light      1   \n",
       "\n",
       "   rating  aroma  body  flavor  aftertaste  acidity  \n",
       "0      93    9.0   9.0     9.0         8.0      8.0  \n",
       "1      92    9.0   8.0     9.0         8.0      8.0  \n",
       "2      96    9.0   9.0    10.0         9.0      9.0  \n",
       "3      95    9.0   9.0     9.0         9.0      9.0  \n",
       "4      95    9.0   9.0     9.0         9.0      9.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.loc[(combined.aroma == 'NR')|(combined.aroma == 'NA'),'aroma'] = '-999'\n",
    "combined.aroma = combined.aroma.astype(float)\n",
    "combined.aroma = combined.aroma.round(0)\n",
    "\n",
    "combined.loc[(combined.body == 'NR')|(combined.body == 'NA'),'body'] = '-999'\n",
    "combined.body = combined.body.astype(float)\n",
    "combined.body = combined.body.round(0)\n",
    "\n",
    "combined.loc[(combined.flavor == 'NR')|(combined.flavor == 'NA'),'flavor'] = '-999'\n",
    "combined.flavor = combined.flavor.astype(float)\n",
    "combined.flavor = combined.flavor.round(0)\n",
    "\n",
    "combined.aftertaste.fillna('-999',inplace=True)\n",
    "combined.aftertaste = combined.aftertaste.astype(float)\n",
    "combined.aftertaste = combined.aftertaste.round(0)\n",
    "\n",
    "combined.loc[(combined.acidity == 'NR')|(combined.acidity == 'NA')|(combined.acidity == 'na')|(combined.acidity == 'n/a'),'acidity'] = '-999'\n",
    "combined.loc[(combined.acidity == 'Very Low'),'acidity'] = '1'\n",
    "combined.loc[(combined.acidity == 'Low'),'acidity'] = '3'\n",
    "combined.loc[(combined.acidity == 'Moderate'),'acidity'] = '5'\n",
    "combined.acidity.fillna(-999,inplace=True)\n",
    "combined.acidity = combined.acidity.astype(float)\n",
    "combined.acidity = combined.acidity.round(0)\n",
    "\n",
    "combined.dropna(subset=['rating','aroma','body','flavor','aftertaste','acidity'],axis=0,inplace=True)\n",
    "# pd.get_dummies(combined,columns=['group'])\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
